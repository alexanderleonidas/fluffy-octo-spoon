{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory Data Analysis (EDA) for Food Reviews Dataset",
   "id": "8bb661b62f3d1dda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Overview of the Datasets\n",
   "id": "4e6bde2cde4f365b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the datasets",
   "id": "445ca67f3ce29e2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:00:38.983374Z",
     "start_time": "2026-02-12T17:00:32.927457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV and TXT files\n",
    "bad_lines = []\n",
    "def collect_bad_line(line):\n",
    "    bad_lines.append(line)\n",
    "    return None  # skip\n",
    "\n",
    "nutrition_df = pd.read_csv('data/Nutrition.csv', sep=\";\")\n",
    "restaurants_df = pd.read_csv('data/Restaurants.csv', sep=\";\")\n",
    "reviews_df = pd.read_csv('data/Reviews.txt', sep=\"\\t\")\n",
    "recipes_df = pd.read_csv(\"data/Recipes.csv\", sep=\";\", engine=\"python\", on_bad_lines=collect_bad_line)\n",
    "\n",
    "print(\"loaded:\", recipes_df.shape)\n",
    "print(\"bad lines captured:\", len(bad_lines))\n",
    "print(\"example bad line:\", bad_lines[0][:2000] if bad_lines else \"none\")\n"
   ],
   "id": "3c9ebd378ebbff2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: (402037, 13)\n",
      "bad lines captured: 0\n",
      "example bad line: none\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recipes Dataset",
   "id": "47ca085326c00518"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T17:00:40.928156Z",
     "start_time": "2026-02-12T17:00:38.984590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('====== Recipes Dataset ======')\n",
    "print('Number of rows: ', recipes_df.shape[0])\n",
    "print('Number of columns: ', recipes_df.shape[1])\n",
    "print('Number of Unique Recipe Categories: ', len(list(set(recipes_df['RecipeCategory'].unique()))))\n",
    "print('Number of Unique DatePublished: ', len(list(set(recipes_df['DatePublished'].unique()))))\n",
    "print('Number of duplicates: ', recipes_df.duplicated().sum())\n",
    "print('Number of Null Values: ', recipes_df.isnull().sum().sum())\n",
    "print('Number of rows with null values: ', len(recipes_df[recipes_df.isnull().any(axis=1)].index))\n",
    "print('Columns with Null Values: ', recipes_df.isnull().sum())\n",
    "print('\\n')\n",
    "recipes_df.head()\n"
   ],
   "id": "9ad34a5651175932",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Recipes Dataset ======\n",
      "Number of rows:  402037\n",
      "Number of columns:  13\n",
      "Number of Unique Recipe Categories:  295\n",
      "Number of Unique DatePublished:  146107\n",
      "Number of duplicates:  0\n",
      "Number of Null Values:  500854\n",
      "Number of rows with null values:  360568\n",
      "Columns with Null Values:  RecipeId                           0\n",
      "Name                               0\n",
      "CookTime                       65291\n",
      "PrepTime                           0\n",
      "DatePublished                      0\n",
      "Images                             1\n",
      "RecipeCategory                   449\n",
      "Keywords                       10909\n",
      "RecipeIngredientQuantities         2\n",
      "RecipeIngredientParts              0\n",
      "RecipeServings                145767\n",
      "RecipeYield                   278435\n",
      "RecipeInstructions                 0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   RecipeId                               Name CookTime PrepTime  \\\n",
       "0        38  Low-Fat Berry Blue Frozen Dessert    PT24H    PT45M   \n",
       "1        39                            Biryani    PT25M     PT4H   \n",
       "2        40                      Best Lemonade     PT5M    PT30M   \n",
       "3        41     Carina's Tofu-Vegetable Kebabs    PT20M    PT24H   \n",
       "4        42                       Cabbage Soup    PT30M    PT20M   \n",
       "\n",
       "          DatePublished                                             Images  \\\n",
       "0  1999-08-09T21:46:00Z  c(\"https://img.sndimg.com/food/image/upload/w_...   \n",
       "1  1999-08-29T13:12:00Z  c(\"https://img.sndimg.com/food/image/upload/w_...   \n",
       "2  1999-09-05T19:52:00Z  c(\"https://img.sndimg.com/food/image/upload/w_...   \n",
       "3  1999-09-03T14:54:00Z  c(\"https://img.sndimg.com/food/image/upload/w_...   \n",
       "4  1999-09-19T06:19:00Z  \"https://img.sndimg.com/food/image/upload/w_55...   \n",
       "\n",
       "    RecipeCategory                                           Keywords  \\\n",
       "0  Frozen Desserts  c(\"Dessert\", \"Low Protein\", \"Low Cholesterol\",...   \n",
       "1   Chicken Breast  c(\"Chicken Thigh & Leg\", \"Chicken\", \"Poultry\",...   \n",
       "2        Beverages  c(\"Low Protein\", \"Low Cholesterol\", \"Healthy\",...   \n",
       "3         Soy/Tofu  c(\"Beans\", \"Vegetable\", \"Low Cholesterol\", \"We...   \n",
       "4        Vegetable  c(\"Low Protein\", \"Vegan\", \"Low Cholesterol\", \"...   \n",
       "\n",
       "                          RecipeIngredientQuantities  \\\n",
       "0                            c(\"4\", \"1/4\", \"1\", \"1\")   \n",
       "1  c(\"1\", \"4\", \"2\", \"2\", \"8\", \"1/4\", \"8\", \"1/2\", ...   \n",
       "2            c(\"1 1/2\", \"1\", NA, \"1 1/2\", NA, \"3/4\")   \n",
       "3  c(\"12\", \"1\", \"2\", \"1\", \"10\", \"1\", \"3\", \"2\", \"2...   \n",
       "4                        c(\"46\", \"4\", \"1\", \"2\", \"1\")   \n",
       "\n",
       "                               RecipeIngredientParts  RecipeServings  \\\n",
       "0  c(\"blueberries\", \"granulated sugar\", \"vanilla ...             4.0   \n",
       "1  c(\"saffron\", \"milk\", \"hot green chili peppers\"...             6.0   \n",
       "2  c(\"sugar\", \"lemons, rind of\", \"lemon, zest of\"...             4.0   \n",
       "3  c(\"extra firm tofu\", \"eggplant\", \"zucchini\", \"...             2.0   \n",
       "4  c(\"plain tomato juice\", \"cabbage\", \"onion\", \"c...             4.0   \n",
       "\n",
       "  RecipeYield                                 RecipeInstructions  \n",
       "0         NaN  c(\"Toss 2 cups berries with sugar.\", \"Let stan...  \n",
       "1         NaN  c(\"Soak saffron in warm milk for 5 minutes and...  \n",
       "2         NaN  c(\"Into a 1 quart Jar with tight fitting lid, ...  \n",
       "3    4 kebabs  c(\"Drain the tofu, carefully squeezing out exc...  \n",
       "4         NaN  c(\"Mix everything together and bring to a boil...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Name</th>\n",
       "      <th>CookTime</th>\n",
       "      <th>PrepTime</th>\n",
       "      <th>DatePublished</th>\n",
       "      <th>Images</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>RecipeIngredientQuantities</th>\n",
       "      <th>RecipeIngredientParts</th>\n",
       "      <th>RecipeServings</th>\n",
       "      <th>RecipeYield</th>\n",
       "      <th>RecipeInstructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>Low-Fat Berry Blue Frozen Dessert</td>\n",
       "      <td>PT24H</td>\n",
       "      <td>PT45M</td>\n",
       "      <td>1999-08-09T21:46:00Z</td>\n",
       "      <td>c(\"https://img.sndimg.com/food/image/upload/w_...</td>\n",
       "      <td>Frozen Desserts</td>\n",
       "      <td>c(\"Dessert\", \"Low Protein\", \"Low Cholesterol\",...</td>\n",
       "      <td>c(\"4\", \"1/4\", \"1\", \"1\")</td>\n",
       "      <td>c(\"blueberries\", \"granulated sugar\", \"vanilla ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c(\"Toss 2 cups berries with sugar.\", \"Let stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>Biryani</td>\n",
       "      <td>PT25M</td>\n",
       "      <td>PT4H</td>\n",
       "      <td>1999-08-29T13:12:00Z</td>\n",
       "      <td>c(\"https://img.sndimg.com/food/image/upload/w_...</td>\n",
       "      <td>Chicken Breast</td>\n",
       "      <td>c(\"Chicken Thigh &amp; Leg\", \"Chicken\", \"Poultry\",...</td>\n",
       "      <td>c(\"1\", \"4\", \"2\", \"2\", \"8\", \"1/4\", \"8\", \"1/2\", ...</td>\n",
       "      <td>c(\"saffron\", \"milk\", \"hot green chili peppers\"...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c(\"Soak saffron in warm milk for 5 minutes and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>Best Lemonade</td>\n",
       "      <td>PT5M</td>\n",
       "      <td>PT30M</td>\n",
       "      <td>1999-09-05T19:52:00Z</td>\n",
       "      <td>c(\"https://img.sndimg.com/food/image/upload/w_...</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>c(\"Low Protein\", \"Low Cholesterol\", \"Healthy\",...</td>\n",
       "      <td>c(\"1 1/2\", \"1\", NA, \"1 1/2\", NA, \"3/4\")</td>\n",
       "      <td>c(\"sugar\", \"lemons, rind of\", \"lemon, zest of\"...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c(\"Into a 1 quart Jar with tight fitting lid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>Carina's Tofu-Vegetable Kebabs</td>\n",
       "      <td>PT20M</td>\n",
       "      <td>PT24H</td>\n",
       "      <td>1999-09-03T14:54:00Z</td>\n",
       "      <td>c(\"https://img.sndimg.com/food/image/upload/w_...</td>\n",
       "      <td>Soy/Tofu</td>\n",
       "      <td>c(\"Beans\", \"Vegetable\", \"Low Cholesterol\", \"We...</td>\n",
       "      <td>c(\"12\", \"1\", \"2\", \"1\", \"10\", \"1\", \"3\", \"2\", \"2...</td>\n",
       "      <td>c(\"extra firm tofu\", \"eggplant\", \"zucchini\", \"...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4 kebabs</td>\n",
       "      <td>c(\"Drain the tofu, carefully squeezing out exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Cabbage Soup</td>\n",
       "      <td>PT30M</td>\n",
       "      <td>PT20M</td>\n",
       "      <td>1999-09-19T06:19:00Z</td>\n",
       "      <td>\"https://img.sndimg.com/food/image/upload/w_55...</td>\n",
       "      <td>Vegetable</td>\n",
       "      <td>c(\"Low Protein\", \"Vegan\", \"Low Cholesterol\", \"...</td>\n",
       "      <td>c(\"46\", \"4\", \"1\", \"2\", \"1\")</td>\n",
       "      <td>c(\"plain tomato juice\", \"cabbage\", \"onion\", \"c...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c(\"Mix everything together and bring to a boil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Nutrition Dataset\n",
   "id": "fdce41bbaeef5d09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:49:40.654976Z",
     "start_time": "2026-02-12T16:49:40.573313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('====== Nutrition Dataset ======')\n",
    "print('Number of rows: ', nutrition_df.shape[0])\n",
    "print('Number of columns: ', nutrition_df.shape[1])\n",
    "unique_recipe_categories = list(set(nutrition_df['RecipeCategory'].unique()))\n",
    "print('Number of Unique Recipe Categories: ', len(unique_recipe_categories))\n",
    "print('Number of duplicates: ', nutrition_df.duplicated().sum())\n",
    "print('Number of Null Values: ', nutrition_df.isnull().sum().sum())\n",
    "print('Number rows with null values: ', [r for r in nutrition_df[nutrition_df.isnull().any(axis=1)].index])\n",
    "print('Columns with Null Values: ', nutrition_df.isnull().sum())\n",
    "print('\\n')\n",
    "nutrition_df.head()"
   ],
   "id": "e64e05a98c254a7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Nutrition Dataset ======\n",
      "Number of rows:  81411\n",
      "Number of columns:  12\n",
      "Number of Unique Recipe Categories:  242\n",
      "Number of duplicates:  3\n",
      "Number of Null Values:  21\n",
      "Number rows with null values:  [1369, 3416, 3526, 3645, 4590, 4591, 75670, 76570, 80674, 80701, 80790, 81410]\n",
      "Columns with Null Values:  Name                   0\n",
      "Description            5\n",
      "RecipeCategory         7\n",
      "Calories               1\n",
      "FatContent             1\n",
      "SaturatedFatContent    1\n",
      "CholesterolContent     1\n",
      "SodiumContent          1\n",
      "CarbohydrateContent    1\n",
      "FiberContent           1\n",
      "SugarContent           1\n",
      "ProteinContent         1\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                Name  \\\n",
       "0  Low-Fat Berry Blue Frozen Dessert   \n",
       "1                            Biryani   \n",
       "2                      Best Lemonade   \n",
       "3     Carina's Tofu-Vegetable Kebabs   \n",
       "4                       Cabbage Soup   \n",
       "\n",
       "                                         Description   RecipeCategory  \\\n",
       "0  Make and share this Low-Fat Berry Blue Frozen ...  Frozen Desserts   \n",
       "1  Make and share this Biryani recipe from Food.com.   Chicken Breast   \n",
       "2  This is from one of my  first Good House Keepi...        Beverages   \n",
       "3  This dish is best prepared a day in advance to...         Soy/Tofu   \n",
       "4  Make and share this Cabbage Soup recipe from F...        Vegetable   \n",
       "\n",
       "   Calories  FatContent  SaturatedFatContent  CholesterolContent  \\\n",
       "0     170.9         2.5                  1.3                 8.0   \n",
       "1    1110.7        58.8                 16.6               372.8   \n",
       "2     311.1         0.2                  0.0                 0.0   \n",
       "3     536.1        24.0                  3.8                 0.0   \n",
       "4     103.6         0.4                  0.1                 0.0   \n",
       "\n",
       "   SodiumContent  CarbohydrateContent  FiberContent  SugarContent  \\\n",
       "0           29.8                 37.1           3.6          30.2   \n",
       "1          368.4                 84.4           9.0          20.4   \n",
       "2            1.8                 81.5           0.4          77.2   \n",
       "3         1558.6                 64.2          17.3          32.1   \n",
       "4          959.3                 25.1           4.8          17.7   \n",
       "\n",
       "   ProteinContent  \n",
       "0             3.2  \n",
       "1            63.4  \n",
       "2             0.3  \n",
       "3            29.3  \n",
       "4             4.3  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low-Fat Berry Blue Frozen Dessert</td>\n",
       "      <td>Make and share this Low-Fat Berry Blue Frozen ...</td>\n",
       "      <td>Frozen Desserts</td>\n",
       "      <td>170.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>37.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>30.2</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biryani</td>\n",
       "      <td>Make and share this Biryani recipe from Food.com.</td>\n",
       "      <td>Chicken Breast</td>\n",
       "      <td>1110.7</td>\n",
       "      <td>58.8</td>\n",
       "      <td>16.6</td>\n",
       "      <td>372.8</td>\n",
       "      <td>368.4</td>\n",
       "      <td>84.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>63.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Lemonade</td>\n",
       "      <td>This is from one of my&nbsp;&nbsp;first Good House Keepi...</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>311.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>81.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>77.2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carina's Tofu-Vegetable Kebabs</td>\n",
       "      <td>This dish is best prepared a day in advance to...</td>\n",
       "      <td>Soy/Tofu</td>\n",
       "      <td>536.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1558.6</td>\n",
       "      <td>64.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>32.1</td>\n",
       "      <td>29.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabbage Soup</td>\n",
       "      <td>Make and share this Cabbage Soup recipe from F...</td>\n",
       "      <td>Vegetable</td>\n",
       "      <td>103.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>959.3</td>\n",
       "      <td>25.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Restaurants Dataset",
   "id": "7ab3963c637a7b64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:49:44.716230Z",
     "start_time": "2026-02-12T16:49:44.643542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('====== Restaurants Dataset ======')\n",
    "print('Number of rows: ', restaurants_df.shape[0])\n",
    "print('Number of columns: ', restaurants_df.shape[1])\n",
    "print('Number of Unique Countries: ', len(list(set(restaurants_df['Country'].unique()))))\n",
    "print('Number of Unique Cuisines: ', len(list(set(restaurants_df['Cuisines'].unique()))))\n",
    "print('Number of duplicates: ', restaurants_df.duplicated().sum())\n",
    "print('Number of Null Values: ', restaurants_df.isnull().sum().sum())\n",
    "print('The rows of the null values: ', [r for r in restaurants_df[restaurants_df.isnull().any(axis=1)].index])\n",
    "print('\\n')\n",
    "restaurants_df.head()"
   ],
   "id": "f0fc83b13a5315d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Restaurants Dataset ======\n",
      "Number of rows:  9550\n",
      "Number of columns:  21\n",
      "Number of Unique Countries:  15\n",
      "Number of Unique Cuisines:  1832\n",
      "Number of duplicates:  0\n",
      "Number of Null Values:  0\n",
      "The rows of the null values:  []\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Restaurant ID       Restaurant Name Country       City  \\\n",
       "0        1600219                 12212   India     Nashik   \n",
       "1       17057397                'Ohana     USA    Orlando   \n",
       "2       18222559  {Niche} - Cafe & Bar   India  New Delhi   \n",
       "3         113702                @Mango   India  Ahmedabad   \n",
       "4        3100446                   #45   India  Mangalore   \n",
       "\n",
       "                                             Address  \\\n",
       "0  Shop 10, Ramrajya Building 7, Samarth Nagar, N...   \n",
       "1  1600 Seven Seas Drive, Lake Buena Vista, FL 32830   \n",
       "2  2nd & 3rd Floor, M-16, M Block, Outer Circle, ...   \n",
       "3        Opposite Sindhu Bhawan, Bodakdev, Ahmedabad   \n",
       "4  Ground Floor, Trinity Commercial Complex, Near...   \n",
       "\n",
       "             Locality Verbose  Longitude   Latitude  \\\n",
       "0        College Road, Nashik  73.754636  20.006690   \n",
       "1  Disney World Area, Orlando -81.585226  28.405437   \n",
       "2  Connaught Place, New Delhi  77.222507  28.631516   \n",
       "3         Bodakdev, Ahmedabad  72.501764  23.040163   \n",
       "4          Attavar, Mangalore   0.000000   0.000000   \n",
       "\n",
       "                                      Cuisines            Currency  ...  \\\n",
       "0                                    Fast Food  Indian Rupees(Rs.)  ...   \n",
       "1                                     Hawaiian           Dollar($)  ...   \n",
       "2  North Indian, Chinese, Italian, Continental  Indian Rupees(Rs.)  ...   \n",
       "3  North Indian, Continental, Mexican, Italian  Indian Rupees(Rs.)  ...   \n",
       "4                                         Cafe  Indian Rupees(Rs.)  ...   \n",
       "\n",
       "   Has Online delivery  Is delivering now  Switch to order menu  Price range  \\\n",
       "0                    0                  0                     0            2   \n",
       "1                    0                  0                     0            3   \n",
       "2                    0                  0                     0            3   \n",
       "3                    0                  0                     0            3   \n",
       "4                    0                  0                     0            2   \n",
       "\n",
       "   Aggregate rating  Rating color  Rating text  Votes  \\\n",
       "0               3.5          3.70            3     80   \n",
       "1               4.5          4.65            5   1151   \n",
       "2               4.1          4.25            4    492   \n",
       "3               4.1          4.25            4    769   \n",
       "4               3.6          3.70            3    209   \n",
       "\n",
       "   Nummber of dishes in cuisines  Average cost of two in USD  \n",
       "0                              1                       4.664  \n",
       "1                              1                      45.000  \n",
       "2                              4                      17.490  \n",
       "3                              4                       9.328  \n",
       "4                              1                       6.996  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant ID</th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Address</th>\n",
       "      <th>Locality Verbose</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Cuisines</th>\n",
       "      <th>Currency</th>\n",
       "      <th>...</th>\n",
       "      <th>Has Online delivery</th>\n",
       "      <th>Is delivering now</th>\n",
       "      <th>Switch to order menu</th>\n",
       "      <th>Price range</th>\n",
       "      <th>Aggregate rating</th>\n",
       "      <th>Rating color</th>\n",
       "      <th>Rating text</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Nummber of dishes in cuisines</th>\n",
       "      <th>Average cost of two in USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600219</td>\n",
       "      <td>12212</td>\n",
       "      <td>India</td>\n",
       "      <td>Nashik</td>\n",
       "      <td>Shop 10, Ramrajya Building 7, Samarth Nagar, N...</td>\n",
       "      <td>College Road, Nashik</td>\n",
       "      <td>73.754636</td>\n",
       "      <td>20.006690</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>Indian Rupees(Rs.)</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>4.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17057397</td>\n",
       "      <td>'Ohana</td>\n",
       "      <td>USA</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>1600 Seven Seas Drive, Lake Buena Vista, FL 32830</td>\n",
       "      <td>Disney World Area, Orlando</td>\n",
       "      <td>-81.585226</td>\n",
       "      <td>28.405437</td>\n",
       "      <td>Hawaiian</td>\n",
       "      <td>Dollar($)</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5</td>\n",
       "      <td>1151</td>\n",
       "      <td>1</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18222559</td>\n",
       "      <td>{Niche} - Cafe &amp; Bar</td>\n",
       "      <td>India</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2nd &amp; 3rd Floor, M-16, M Block, Outer Circle, ...</td>\n",
       "      <td>Connaught Place, New Delhi</td>\n",
       "      <td>77.222507</td>\n",
       "      <td>28.631516</td>\n",
       "      <td>North Indian, Chinese, Italian, Continental</td>\n",
       "      <td>Indian Rupees(Rs.)</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4</td>\n",
       "      <td>492</td>\n",
       "      <td>4</td>\n",
       "      <td>17.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113702</td>\n",
       "      <td>@Mango</td>\n",
       "      <td>India</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Opposite Sindhu Bhawan, Bodakdev, Ahmedabad</td>\n",
       "      <td>Bodakdev, Ahmedabad</td>\n",
       "      <td>72.501764</td>\n",
       "      <td>23.040163</td>\n",
       "      <td>North Indian, Continental, Mexican, Italian</td>\n",
       "      <td>Indian Rupees(Rs.)</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4</td>\n",
       "      <td>769</td>\n",
       "      <td>4</td>\n",
       "      <td>9.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3100446</td>\n",
       "      <td>#45</td>\n",
       "      <td>India</td>\n",
       "      <td>Mangalore</td>\n",
       "      <td>Ground Floor, Trinity Commercial Complex, Near...</td>\n",
       "      <td>Attavar, Mangalore</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>Indian Rupees(Rs.)</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "      <td>6.996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for idx, row in restaurants_df.iterrows():\n",
    "    q = row['Cuisines']\n",
    "    for u in unique_recipe_categories:\n",
    "        if u == q:\n",
    "            print(f\"Found a match in row {index} with category {u} and cuisine {q}\")\n",
    "    if idx > 20: break"
   ],
   "id": "8f3be6b0ff9de4d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reviews Dataset\n",
    "This is the unstructured dataset that contains the reviews from users. the reviews are supposed to be on a single line, however this is not the case and a single review may be split up into more than one line."
   ],
   "id": "af022cacc8a2178c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('====== Reviews Dataset ======')\n",
    "print('Number of rows: ', reviews_df.shape[0])\n",
    "print('Number of columns: ', reviews_df.shape[1])\n",
    "print('Number of Unique Authors: ', len(list(set(reviews_df['AuthorId'].unique()))))\n",
    "print('Number of duplicates: ', reviews_df.duplicated().sum())\n",
    "print('Number of Null Values: ', reviews_df.isnull().sum().sum())\n",
    "print('Number of rows with null values: ', len(reviews_df[reviews_df.isnull().any(axis=1)].index))\n",
    "print('Columns with Null Values: \\n', reviews_df.isnull().sum())\n",
    "print('\\n')\n",
    "reviews_df.head(20)"
   ],
   "id": "a31f7fa4b4f799f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# reviews that have recipe ids that are not present in the recipes dataset\n",
    "invalid_reviews = reviews_df[reviews_df['RecipeId'].isin(recipes_df['RecipeId'])]\n",
    "print('Number of reviews with invalid recipe ids: ', invalid_reviews.shape[0])"
   ],
   "id": "5cabc28ef93cca68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cleaning the Datasets\n",
    "With every single dataset we will have to clean it in order to make it suitable for the construction of the knowledge graph. In all datasets duplicated rows are removed. Null values are treated accordingly based on the importance of the attribute. Also, only recipes which have nutritional information are kept, therefore, keeping only recipes that are present in both the Recipes and Nutrition datasets.\n",
    "\n",
    "#### Relevant Columns in each dataset:\n",
    "- For the **Recipe dataset**, <u>remove</u> the `RecipeYield`, `RecipeServings`, and `Images` columns as they are not relevant to the task. Replace the null values in the `CookTime` column with the median cook time. Also, <u>remove</u> the rows that have the null values in the `RecipeCategory` and `Keywords` column as they are crucial attributes for the knowledge graph.\n",
    "\n",
    "- In the **Nutrition dataset**, <u>keep</u> all the columns as they are relevant to the construction of the knowledge graph. But <u>remove</u> the rows that do not have a `RecipeCategory` value and nutritional values.\n",
    "\n",
    "- In the **Restaurants dataset**, <u>remove</u> the `Is delivering now`, `Switch to order menu`, `Price range`, `Rating color`, `Rating text`, `Longitude`, `Latitude` and `Nummber of dishes in cuisines` columns as they are not relevant to the task.\n",
    "\n",
    "- The **Reviews dataset**, which is unstructured, is preprocessed to deal with all the reviews that are split into multiple lines and columns. All columns are <u>kept</u>."
   ],
   "id": "bb490dfdb40dc054"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remove duplicates from all the datasets\n",
    "recipes_df.drop_duplicates(inplace=True)\n",
    "restaurants_df.drop_duplicates(inplace=True)\n",
    "nutrition_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove irrelevant columns from the datasets\n",
    "recipes_df.drop(columns=[\"RecipeYield\", \"RecipeServings\", \"Images\"], inplace=True)\n",
    "restaurants_df.drop(columns=[\"Is delivering now\", \"Switch to order menu\", \"Price range\", \"Nummber of dishes in cuisines\", \"Rating color\", \"Rating text\", \"Longitude\", \"Latitude\"], inplace=True)\n",
    "\n",
    "# Remove rows with null values in the RecipeCategory and Keywords columns in the Recipes dataset\n",
    "recipes_df.dropna(subset=['RecipeCategory', 'Keywords', 'RecipeIngredientQuantities'], inplace=True)\n",
    "nutrition_df.dropna(inplace=True) # remove rows with null values in the Nutrition dataset\n",
    "\n",
    "# Remove all the recipes in the Recipes dataset that are not present in the Nutrition dataset\n",
    "recipes_df = recipes_df[recipes_df['Name'].isin(nutrition_df['Name'])]\n",
    "\n",
    "# Clean the Keywords by removing the parentheses and double quotes from the keywords\n",
    "for i , v in recipes_df.iterrows():\n",
    "    v['Keywords'] = v['Keywords'].replace('(', '').replace(')', '').replace('\"','')\n",
    "    v['Keywords'] = v['Keywords'][1:]"
   ],
   "id": "8f7396a7cf63da97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Clean the cook and prep times of the Recipes dataset\n",
    "def clean_cook_time_column(df, column):\n",
    "    for index, row in df.iterrows(): # iterate through each row in the dataframe\n",
    "        minutes = 0 # initialise the minutes variable\n",
    "        time_str = row[column] # get the cook time string\n",
    "        if pd.isna(time_str): # if the cook time value is null, skip the row\n",
    "            df.at[index, column] = str(0)\n",
    "            continue\n",
    "        time_str = time_str.replace('PT', '') # remove the 'PT' prefix from the cook time values\n",
    "        for char in time_str: # iterate through each character in the cook time string\n",
    "            if char == \"H\":\n",
    "                minutes += int(time_str[:time_str.index(char)]) * 60 # add the hours to the minutes variable\n",
    "                time_str = time_str[time_str.index(char)+1:]\n",
    "            elif char == \"M\":\n",
    "                minutes += int(time_str[:time_str.index(char)]) # add the minutes to the minutes variable\n",
    "        df.at[index, column] = str(minutes) # replace the cook time string with the minutes variable\n",
    "    df[column] = pd.to_numeric(df[column], downcast='float') # convert the cook time values to numeric\n",
    "    df[column].fillna(df[column].median()) # replace null cook time values with median time\n",
    "\n",
    "# Convert CookTime and PrepTime to numeric and replace null values with median\n",
    "clean_cook_time_column(recipes_df, 'CookTime')\n",
    "clean_cook_time_column(recipes_df, 'PrepTime')"
   ],
   "id": "5fd4145a5c46d088"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Clean the Reviews dataset",
   "id": "9929f2043c75fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# String Type Constants\n",
    "NL = 0\n",
    "DT = 1\n",
    "Z = 2\n",
    "NULL = 3\n",
    "\n",
    "\n",
    "def is_datetime_string(s):\n",
    "    if isinstance(s, str) and len(s) == 20 and s[4] == '-' and s[7] == '-':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_line_and_split(line):\n",
    "    # remove the double quotes from the line and split it by tab character\n",
    "    line = line.replace('\"\"\"', \"\").replace('\"\"', \"\").replace('\"', \"\")\n",
    "    split_line = line.split(\"\\t\") # split the line based on the tab character\n",
    "    split_line = [s.strip() for s in split_line] # remove leading and trailing whitespace from each element\n",
    "    return split_line\n",
    "\n",
    "def get_string_types_from_split_line(row: list[str]):\n",
    "    string_types = []\n",
    "    for i in row:\n",
    "        if i == '' or i is None or i.lower() == 'nan':\n",
    "            string_types.append(NULL)\n",
    "        elif is_datetime_string(i):\n",
    "            string_types.append(DT)\n",
    "        elif i.isdigit():\n",
    "            string_types.append(Z)\n",
    "        else:\n",
    "            string_types.append(NL)\n",
    "    return string_types\n",
    "\n",
    "# Check if a row is in the correct order of the column types\n",
    "def check_correct_row_order(row: list[str]):\n",
    "    st = get_string_types_from_split_line(row)\n",
    "    if len(st) == len(row) == 7 and st[0] == Z and st[1] == Z and st[2] == Z and st[3] == NL and st[4] == NL and st[5] == DT and st[6] == DT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Function to make the row from an initial line. It iteratively builds and cleans rows until the correct order is achieved\n",
    "def make_row(all_lines, line_idx, line_string):\n",
    "    sl = clean_line_and_split(line_string)\n",
    "    # print(sl)\n",
    "    # Merge the reviews that have been split into multiple lines or columns\n",
    "    row = [None for _ in range(7)] # new row to store the cleaned data\n",
    "    review = \"\" # string to store the review text\n",
    "    date1, date2 = None, None # strings to store the first and second datetime\n",
    "    for n, col in enumerate(sl):\n",
    "        if col.isdigit() and n < 3: # the first three columns ReviewID, RecipeID, AuthorID should be numeric values\n",
    "                row[n] = col\n",
    "        elif n == 3 and not col.isdigit() and not is_datetime_string(col): # the fourth should be the AuthorName column\n",
    "            row[n] = col\n",
    "        else:\n",
    "            if not is_datetime_string(col):\n",
    "                review += \" \" + col\n",
    "            else:\n",
    "                if not date1 and col != '':\n",
    "                    date1 = col\n",
    "                elif not date2 and date1 and col != '':\n",
    "                    date2 = col\n",
    "    st_1 = get_string_types_from_split_line(sl)\n",
    "\n",
    "    # If the previous row had only natural language, empty values and integers and no datetime strings, then we can merge the next\n",
    "    # row with the current row depending on whether the next row has only datetime strings or natural language and empty values\n",
    "    next_row_idx = line_idx + 1\n",
    "    while date1 is None and date2 is None and next_row_idx < len(all_lines):\n",
    "        if st_1.count(NL) + st_1.count(NULL) + st_1.count(Z) == len(st_1):\n",
    "        # if not check_correct_row_order(sl):\n",
    "        #     print('next row needs to be checked')\n",
    "            # Get the next line\n",
    "            next_line = clean_line_and_split(all_lines[next_row_idx])\n",
    "            st_2 = get_string_types_from_split_line(next_line)\n",
    "            # If the next row ha sonly natural language, then merge the text into the review column\n",
    "            if st_2.count(NL) + st_2.count(NULL) == len(st_2):\n",
    "                review += \" \".join(next_line)\n",
    "            # If the next row has only datetime strings, then merge the datetime into the date columns\n",
    "            if st_2.count(DT) + st_2.count(NULL) == len(st_2):\n",
    "                extracted_dates = [i for i in next_line if is_datetime_string(i)]\n",
    "                date1 = extracted_dates[0]\n",
    "                date2 = extracted_dates[1] if len(extracted_dates) > 1 else date1\n",
    "            # If the next row has both natural language and datetime strings\n",
    "            if st_2.count(NL) + st_2.count(DT) + st_2.count(NULL) == len(st_2) and st_2.count(DT) != 0 and st_2.count(NL) != 0:\n",
    "                extracted_dates = [i for i in next_line if is_datetime_string(i)]\n",
    "                date1 = extracted_dates[0]\n",
    "                date2 = extracted_dates[1] if len(extracted_dates) > 1 else date1\n",
    "                review += \" \".join([i for i in next_line if not is_datetime_string(i) and i != '' and i is not None])\n",
    "        next_row_idx += 1\n",
    "\n",
    "    row[4] = review.strip()\n",
    "    row[5] = date1\n",
    "    row[6] = date2\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "clean_reviews = []\n",
    "with open('data/Reviews.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    # print('First 5 lines of the Reviews.txt file:')\n",
    "    for idx, line in enumerate(lines):\n",
    "        if idx == 0: continue # skip the header line\n",
    "        # print(f'======== Line {idx} =======')\n",
    "        row = make_row(lines, idx, line)\n",
    "        if check_correct_row_order(row):\n",
    "            clean_reviews.append(row)\n",
    "\n",
    "        # print(st_1)\n",
    "        # print(row)\n",
    "\n",
    "\n",
    "clean_reviews = pd.DataFrame(clean_reviews, columns=['ReviewId', 'RecipeId', 'AuthorId', 'AuthorName', 'Review', 'DateSubmitted', 'DateModified'])\n",
    "print(f'Reduced to {len(clean_reviews)} rows from {reviews_df.shape[0]}')\n",
    "print('Number of rows: ', clean_reviews.shape[0])\n",
    "print('Number of columns: ', clean_reviews.shape[1])\n",
    "print('Number of Unique Authors: ', len(list(set(clean_reviews['AuthorId'].unique()))))\n",
    "print('Number of duplicates: ', clean_reviews.duplicated().sum())\n",
    "print('Number of Null Values: ', clean_reviews.isnull().sum().sum())\n",
    "print('Number of rows with null values: ', len(clean_reviews[clean_reviews.isnull().any(axis=1)].index))\n",
    "print('Columns with Null Values: \\n', clean_reviews.isnull().sum())\n",
    "print('\\n')\n",
    "clean_reviews.head()\n"
   ],
   "id": "28645d673f84ca04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save datasets",
   "id": "44653bbe454fd64e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T21:44:55.699528Z",
     "start_time": "2026-02-10T21:44:53.473253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recipes_df.to_csv('data/cleaned_recipes.csv', index=False)\n",
    "nutrition_df.to_csv('data/cleaned_nutrition.csv', index=False)\n",
    "restaurants_df.to_csv('data/cleaned_restaurants.csv', index=False)\n",
    "clean_reviews.to_csv('data/cleaned_reviews.csv', index=False)"
   ],
   "id": "ab4c3a57c341bf3",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
