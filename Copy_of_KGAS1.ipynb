{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkBSCzUoa34G",
    "outputId": "5ff4efbd-369d-4c5b-8eae-9e0ec73faed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in .\\.venv\\Lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in .\\.venv\\Lib\\site-packages (from rdflib) (3.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdflib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9axW4Jnah97",
    "outputId": "6f732de4-cb73-4701-b662-9374ba959d1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from rdflib import Graph, Literal, RDF, RDFS, Namespace, URIRef\n",
    "\n",
    "#Namespaces\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "KG = Namespace(\"http://kg-course.io/food-nutrition/\")\n",
    "\n",
    "g = Graph()\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "g.bind(\"ex\", KG)\n",
    "\n",
    "#Classes\n",
    "classes = [\n",
    "    (KG.Recipe, SCHEMA.Recipe, \"A food recipe\"),\n",
    "    (KG.Restaurant, SCHEMA.FoodEstablishment, \"An enstablishment that serves food\"),\n",
    "    (KG.Nutrition, SCHEMA.NutritionInformation, \"Nutritional facts about a recipe\"),\n",
    "    (KG.Review, SCHEMA.Review, \"A user review\")\n",
    "]\n",
    "\n",
    "for uri, s_type, comment in classes:\n",
    "    g.add((uri, RDF.type, RDFS.Class))\n",
    "    g.add((uri, RDFS.subClassOf, s_type))\n",
    "    g.add((uri, RDFS.comment, Literal(comment)))\n",
    "\n",
    "\n",
    "with open(\"vocabulary.ttl\", \"w\") as f:\n",
    "    f.write(g.serialize(format=\"turtle\"))\n",
    "\n",
    "print(\"Vocabulary defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxSXatilbPUK",
    "outputId": "27c57362-7a73-443e-e0a9-717736c6b2e8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVnlXzWEbELR",
    "outputId": "dae3a259-424f-48d8-abab-b91013e60a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from Drive!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdflib import Graph, Literal, RDF, Namespace, URIRef\n",
    "from rdflib.namespace import XSD\n",
    "\n",
    "# graph and namespaces\n",
    "g = Graph()\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "KG = Namespace(\"http://kg-course.io/food-nutrition/\")\n",
    "g.bind(\"schema\", SCHEMA)\n",
    "g.bind(\"ex\", KG)\n",
    "\n",
    "recipes_df = pd.read_csv('data/Recipes.csv', sep=';', engine='python', on_bad_lines='skip').head(10000)\n",
    "restaurants_df = pd.read_csv('data/Restaurants.csv', sep=';', engine='python', on_bad_lines='skip').head(10000)\n",
    "nutrition_df = pd.read_csv('data/Nutrition.csv', sep=';', engine='python', on_bad_lines='skip').head(10000)\n",
    "\n",
    "print(\"Data loaded successfully from Drive!\")\n",
    "\n",
    "def create_kg():\n",
    "    for index, row in recipes_df.iterrows():\n",
    "        recipe_uri = KG[f\"recipe_{row['RecipeId']}\"]\n",
    "        g.add((recipe_uri, RDF.type, SCHEMA.Recipe))\n",
    "        g.add((recipe_uri, SCHEMA.name, Literal(row['Name'])))\n",
    "        g.add((recipe_uri, SCHEMA.recipeCategory, Literal(row['RecipeCategory'])))\n",
    "        g.add((recipe_uri, SCHEMA.cookTime, Literal(row['CookTime'])))\n",
    "\n",
    "        nutri_uri = KG[f\"nutrition_{row['RecipeId']}\"]\n",
    "        g.add((recipe_uri, SCHEMA.nutrition, nutri_uri))\n",
    "        g.add((nutri_uri, RDF.type, SCHEMA.NutritionInformation))\n",
    "\n",
    "    for index, row in restaurants_df.iterrows():\n",
    "        rest_uri = KG[f\"restaurant_{row['Restaurant.ID']}\"]\n",
    "        g.add((rest_uri, RDF.type, SCHEMA.FoodEstablishment))\n",
    "        g.add((rest_uri, SCHEMA.name, Literal(row['Restaurant.Name'])))\n",
    "        g.add((rest_uri, SCHEMA.address, Literal(row['Address'])))\n",
    "        g.add((rest_uri, SCHEMA.servesCuisine, Literal(row['Cuisines'])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    g.serialize(destination='KEN4256-structured-KG-TeamID.ttl', format='turtle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Enriching graph with unstructured data and external KGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:44:49.030358400Z",
     "start_time": "2026-02-10T18:44:49.006987900Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# reviews_df = pd.read_csv(\"data/cleaned_reviews.csv\")\n",
    "\n",
    "\n",
    "text = [\"I have made this pie instead of plain ol' pumpkin pie for the last 7 years.  Everyone always raves about it.  The flavor is wonderful and the texture is slightly lighter than traditional pumpin pie\\\"\t I suspect due to the substitution of light cream instead of canned milk.  \tIf you try this\t\\\" you won't go back to plain ol' pumkin again!\", \"I hate this freaking recipe it's the worst thing i've every eaten in my life crazy\", \"I don't know, it seems fine, but nothing special really. I don't know what to think about it\", \"I decided to add milk chocolate and it resulted in a more colourful flavour!\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Extracting knowledge from unstructured data\n",
    "WiP: So far I have a few options: using an llm(might be not feasible because on a scale of thousands of reviews we are most likely going to exceed free api limit, unless the OPENAI key provided in the lab includes these costs) or just connect all extracted features to the recipe with a single relation(e.g. ex:extractedIngredients or ex:mentionedIngredients). Second approach is not as high-quality, but might be enough for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:27:45.136649100Z",
     "start_time": "2026-02-10T18:27:39.780809800Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install spacy_llm\n",
    "!pip install langchain\n",
    "!pip install langchain-openai\n",
    "!pip install dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:44:52.820161100Z",
     "start_time": "2026-02-10T18:44:52.726667900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import set_key, load_dotenv\n",
    "\n",
    "with open(\"OPENAI_API_KEY.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip().strip('\"')\n",
    "\n",
    "set_key('.env', 'OPENAI_API_KEY', api_key)\n",
    "\n",
    "# Bring environment variables from .env into os.environ\n",
    "load_dotenv(override=True)\n",
    "print(os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:44:58.395960100Z",
     "start_time": "2026-02-10T18:44:52.840369Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy_llm.util import assemble\n",
    "import spacy\n",
    "\n",
    "nlp = assemble(\"config/lab3_config_rel_1.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:45:00.489425600Z",
     "start_time": "2026-02-10T18:44:58.412351700Z"
    }
   },
   "outputs": [],
   "source": [
    "# consider adding RECIPE_ID to the review text, so that model can have an object for relation (RECIPE_ID [addition] Chocolate milk)\n",
    "doc = nlp(\". \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:45:00.546006100Z",
     "start_time": "2026-02-10T18:45:00.502996200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I have made this pie instead of plain ol' \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pumpkin pie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       "[ENT0:INGREDIENT] for the last 7 years.  Everyone always raves about it.  The flavor is wonderful and the texture is slightly lighter than traditional pumpin pie&quot;\t I suspect due to the substitution of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    light cream\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       "[ENT1:INGREDIENT] instead of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    canned milk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       "[ENT2:INGREDIENT].  \tIf you try this\t&quot; you won't go back to plain ol' pumkin again!. I hate this freaking recipe it's the worst thing i've every eaten in my life crazy. I don't know, it seems fine, but nothing special really. I don't know what to think about it. I decided to add \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    milk chocolate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       "[ENT3:INGREDIENT] and it resulted in a more colourful flavour!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc,jupyter=1, style = \"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:45:00.571703400Z",
     "start_time": "2026-02-10T18:45:00.554242500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - light cream [substitution] canned milk\n",
      "  - milk chocolate [addition] pumpkin pie\n"
     ]
    }
   ],
   "source": [
    "triples = []\n",
    "for r in doc._.rel:\n",
    "        print(f\"  - {doc.ents[r.dep]} [{r.relation}] {doc.ents[r.dest]}\")\n",
    "        triples.append((doc.ents[r.dep].text, r.relation, doc.ents[r.dest].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Sentiment Analysis\n",
    "For the Sentiment analysis we are going to use [cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) classification model. It was trained on posts from Twitter, which are short and often informal, which makes them similar to reviews, so this model is a perfect fit for our needs. The model output has 3 labels: Negative, Neutral, Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:45:01.720240800Z",
     "start_time": "2026-02-10T18:45:00.583930500Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:45:02.401343100Z",
     "start_time": "2026-02-10T18:45:01.740740500Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:45:02.424039300Z",
     "start_time": "2026-02-10T18:45:02.415561300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use softmax to normalize the output to probability distribution\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example(until data cleaning code is finished. After that we will be using dataframe from cleaned_reviews.scv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:45:02.565070100Z",
     "start_time": "2026-02-10T18:45:02.425078800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review\n",
      "0  I have made this pie instead of plain ol' pump...\n",
      "1  I hate this freaking recipe it's the worst thi...\n",
      "2  I don't know, it seems fine, but nothing speci...\n",
      "3  I decided to add milk chocolate and it resulte...\n"
     ]
    }
   ],
   "source": [
    "reviews_df = pd.DataFrame({\"Review\": text})\n",
    "print(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 201/201 [00:00<00:00, 1291.40it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.pooler.dense.weight     | UNEXPECTED |  | \n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "roberta.pooler.dense.bias       | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# Using tokenizer and config provided by the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review Sentiment\n",
      "0  I have made this pie instead of plain ol' pump...  positive\n",
      "1  I hate this freaking recipe it's the worst thi...  negative\n",
      "2  I don't know, it seems fine, but nothing speci...   neutral\n",
      "3  I decided to add milk chocolate and it resulte...  positive\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "output = model(**encoded_input)\n",
    "\n",
    "scores = output[0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores, axis=1)\n",
    "ranking = np.flip(ranking, axis=1)\n",
    "\n",
    "reviews_df[\"Sentiment\"] = ranking[:, 0]\n",
    "reviews_df[\"Sentiment\"] = reviews_df[\"Sentiment\"].map(lambda x: config.id2label[x])\n",
    "print(reviews_df)\n",
    "\n",
    "# for i in range(len(ranking)):\n",
    "#     for j in range(ranking.shape[1]):\n",
    "#         l = config.id2label[ranking[i][j]]\n",
    "#         s = scores[i][ranking[i][j]]\n",
    "#         print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "#\n",
    "#     print()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
