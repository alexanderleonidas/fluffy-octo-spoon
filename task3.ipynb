{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:57.810093Z",
     "start_time": "2026-02-13T18:45:57.384282Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import warnings"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Enriching graph with unstructured data and external KGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Extracting knowledge from unstructured data\n",
    "This task turned out to be quite complicated. Initially, we consider 3 options: \n",
    "- NER with SpaCy NLP model(e.g. en_core_web_trf)\n",
    "- NER with an LLM\n",
    "- NER+RE with an LLM\n",
    "\n",
    "Models like en_core_web_trf are very optimized and are decent for general purpose, but we only need to extract particular types of entities from reviews which will require retraining.\n",
    "This lefts us with LLMs, which are good, but are limited by API rates, which are usually not enough to process the amount of data we have. Thus, the most logical thing would be to download a lightweight LLM and run it locally, which is thankfully quite straightforward process with SpaCy.\n",
    "\n",
    "The choice of model is the most important part here, as some models may be too heavy to run with limited hardware resources, others, on the other hand, are just not 'smart' enough for out task. It seemed that the optimal model for our needs, among the [available from Spacy](https://spacy.io/api/large-language-models#models-hf), would be Mistral-7B-instruct, which is quite fast and has a good performance. However, due to limited resources we decided to limit ourselves ONLY to NER, no Relation Extraction was made, as it would be to computationally expensive to run on our devices.\n",
    "\n",
    "Unfortunately due to an internal error in SpaCy source code it used some outdated parameter, which mistral model didn't accept, this lead to an error during assemble. The only straightforward way of fixing it was to edit [this file](.venv/Lib/site-packages/spacy_llm/models/hf/mistral.py) in Spacy source code(deleting resume_download=true parameter from \\_\\_init__() method). \n",
    "\n",
    "**NOTE: If you want to run llm inference on your computer, consider that it requires a GPU, extensive amount of RAM and editing aforementioned file.\n",
    "We provide file with results of NER in the [data](data) folder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is commented out to avoid errors during run of the Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:57.826565Z",
     "start_time": "2026-02-13T18:45:57.811016Z"
    }
   },
   "source": [
    "# reviews_df = pd.read_csv(\"data/cleaned_reviews.csv\").head(10000)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:57.837378Z",
     "start_time": "2026-02-13T18:45:57.826932Z"
    }
   },
   "source": [
    "# from spacy_llm.util import assemble\n",
    "# import spacy\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# nlp = assemble(\"config/ner_rel_llm.cfg\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:57.848598Z",
     "start_time": "2026-02-13T18:45:57.838110Z"
    }
   },
   "source": [
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# docs = nlp.pipe(reviews_df[\"Review\"].head(500), batch_size=1)\n",
    "\n",
    "# extracted_entities = []\n",
    "# for doc in tqdm(docs, total=500):\n",
    "#     extracted_entities.append(doc.ents)\n",
    "\n",
    "# reviews_df[\"reviews_ingredients_df\"] = pd.Series(extracted_entities)\n",
    "\n",
    "# reviews_df.to_csv(\"data/extracted_reviews.csv\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:57.852788Z",
     "start_time": "2026-02-13T18:45:57.849459Z"
    }
   },
   "source": [
    "# doc = nlp(\". \".join([\"123: I have made this pie instead of plain ol' pumpkin pie for the last 7 years.  Everyone always raves about it.  The flavor is wonderful and the texture is slightly lighter than traditional pumpin pie\\\"\t I suspect due to the substitution of light cream instead of canned milk.  \tIf you try this\t\\\" you won't go back to plain ol' pumkin again!\", \"I hate this freaking recipe it's the worst thing i've every eaten in my life crazy\", \"I don't know, it seems fine, but nothing special really. I don't know what to think about it\", \"I decided to add milk chocolate and it resulted in a more colourful flavour!\"]))"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean extracted ingredients\n",
    " Format them as list of lower case strings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:57.856119Z",
     "start_time": "2026-02-13T18:45:57.853049Z"
    }
   },
   "source": [
    "def clean_ingredients(value: str):\n",
    "    return [s.lower() for s in value.strip(\"()\").replace(\", \", \",\").split(\",\") if s != '' ]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:58.571409Z",
     "start_time": "2026-02-13T18:45:57.856329Z"
    }
   },
   "source": [
    "reviews_ingredients_df = pd.read_csv(\"data/extracted_reviews.csv\")\n",
    "\n",
    "reviews_ingredients_df[\"extracted_ingredients\"] = reviews_ingredients_df[\"extracted_ingredients\"].map(clean_ingredients, 'ignore')\n",
    "reviews_ingredients_df = reviews_ingredients_df[~reviews_ingredients_df[\"extracted_ingredients\"].isna()]\n",
    "\n",
    "reviews_ingredients_df = reviews_ingredients_df[reviews_ingredients_df[\"extracted_ingredients\"].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "reviews_ingredients_df = reviews_ingredients_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "\n",
    "reviews_ingredients_df"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/lntsbg5s0rb6xqf49sv3bv6w0000gn/T/ipykernel_17735/621182173.py:1: DtypeWarning: Columns (0: extracted_ingredients) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews_ingredients_df = pd.read_csv(\"data/extracted_reviews.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     ReviewId  RecipeId  AuthorId        AuthorName  \\\n",
       "1           9      4523      2046  Gay Gilmore ckpt   \n",
       "5          23      4684      2046  Gay Gilmore ckpt   \n",
       "6          25      3431      2046  Gay Gilmore ckpt   \n",
       "8          33      4053      1986    Kevin Connolly   \n",
       "15         49      2388      2033     Sandy Zikursh   \n",
       "..        ...       ...       ...               ...   \n",
       "487      1310      7776      8571   Kirsti Piironen   \n",
       "489      1319      9427      7802           Mark H.   \n",
       "492      1324      5275     11733            Janet1   \n",
       "493      1325      9492     11297             Jen T   \n",
       "498      1340      9549     11846             Susie   \n",
       "\n",
       "                                                Review         DateSubmitted  \\\n",
       "1    i think i did something wrong because i could ...  2000-02-25T09:00:00Z   \n",
       "5    this is absolutely delicious.  i even served i...  2000-02-25T09:06:00Z   \n",
       "6    leeks on a pizza?!  it was really delicious.  ...  2000-04-07T11:06:00Z   \n",
       "8    This was a fine sandwich I'll definitely be ma...  2000-08-26T12:35:25Z   \n",
       "15   My husbands Aunt Dorothy made the best dumplin...  2000-09-20T13:56:46Z   \n",
       "..                                                 ...                   ...   \n",
       "487  Why would you want to add anything like mayo o...  2001-06-25T10:36:56Z   \n",
       "489  These were very smooth and had a good taste. N...  2001-06-25T15:51:29Z   \n",
       "492  having lived in Australia for 33years we often...  2001-06-25T19:19:34Z   \n",
       "493  So easy and tasty.   To make the clean-up even...  2001-06-26T11:23:50Z   \n",
       "498  This is a great way to cook cornish game hens ...  2001-06-27T11:50:26Z   \n",
       "\n",
       "             DateModified                              extracted_ingredients  \n",
       "1    2000-02-25T09:00:00Z                                       [cornstarch]  \n",
       "5    2000-02-25T09:06:00Z                                      [lime slices]  \n",
       "6    2000-04-07T11:06:00Z  [leeks, pizza, boboli, chicken sausage, mushro...  \n",
       "8    2000-08-26T12:35:25Z                          [blue cheese, roast beef]  \n",
       "15   2000-09-20T13:56:46Z                [mashed potatoes, pork, beef, stew]  \n",
       "..                    ...                                                ...  \n",
       "487  2001-06-25T10:36:56Z                                 [mayo, sour cream]  \n",
       "489  2001-06-25T15:51:29Z                 [smooth, cream cheese, sour cream]  \n",
       "492  2001-06-25T19:19:34Z                      [english faggots, pigs liver]  \n",
       "493  2001-06-26T11:23:50Z                                          [tinfoil]  \n",
       "498  2001-06-27T11:50:26Z  [cornish game hens, vegetables, spices, garlic...  \n",
       "\n",
       "[258 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>AuthorName</th>\n",
       "      <th>Review</th>\n",
       "      <th>DateSubmitted</th>\n",
       "      <th>DateModified</th>\n",
       "      <th>extracted_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>4523</td>\n",
       "      <td>2046</td>\n",
       "      <td>Gay Gilmore ckpt</td>\n",
       "      <td>i think i did something wrong because i could ...</td>\n",
       "      <td>2000-02-25T09:00:00Z</td>\n",
       "      <td>2000-02-25T09:00:00Z</td>\n",
       "      <td>[cornstarch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>4684</td>\n",
       "      <td>2046</td>\n",
       "      <td>Gay Gilmore ckpt</td>\n",
       "      <td>this is absolutely delicious.&nbsp;&nbsp;i even served i...</td>\n",
       "      <td>2000-02-25T09:06:00Z</td>\n",
       "      <td>2000-02-25T09:06:00Z</td>\n",
       "      <td>[lime slices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>3431</td>\n",
       "      <td>2046</td>\n",
       "      <td>Gay Gilmore ckpt</td>\n",
       "      <td>leeks on a pizza?!&nbsp;&nbsp;it was really delicious.&nbsp;&nbsp;...</td>\n",
       "      <td>2000-04-07T11:06:00Z</td>\n",
       "      <td>2000-04-07T11:06:00Z</td>\n",
       "      <td>[leeks, pizza, boboli, chicken sausage, mushro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>4053</td>\n",
       "      <td>1986</td>\n",
       "      <td>Kevin Connolly</td>\n",
       "      <td>This was a fine sandwich I'll definitely be ma...</td>\n",
       "      <td>2000-08-26T12:35:25Z</td>\n",
       "      <td>2000-08-26T12:35:25Z</td>\n",
       "      <td>[blue cheese, roast beef]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49</td>\n",
       "      <td>2388</td>\n",
       "      <td>2033</td>\n",
       "      <td>Sandy Zikursh</td>\n",
       "      <td>My husbands Aunt Dorothy made the best dumplin...</td>\n",
       "      <td>2000-09-20T13:56:46Z</td>\n",
       "      <td>2000-09-20T13:56:46Z</td>\n",
       "      <td>[mashed potatoes, pork, beef, stew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1310</td>\n",
       "      <td>7776</td>\n",
       "      <td>8571</td>\n",
       "      <td>Kirsti Piironen</td>\n",
       "      <td>Why would you want to add anything like mayo o...</td>\n",
       "      <td>2001-06-25T10:36:56Z</td>\n",
       "      <td>2001-06-25T10:36:56Z</td>\n",
       "      <td>[mayo, sour cream]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1319</td>\n",
       "      <td>9427</td>\n",
       "      <td>7802</td>\n",
       "      <td>Mark H.</td>\n",
       "      <td>These were very smooth and had a good taste. N...</td>\n",
       "      <td>2001-06-25T15:51:29Z</td>\n",
       "      <td>2001-06-25T15:51:29Z</td>\n",
       "      <td>[smooth, cream cheese, sour cream]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1324</td>\n",
       "      <td>5275</td>\n",
       "      <td>11733</td>\n",
       "      <td>Janet1</td>\n",
       "      <td>having lived in Australia for 33years we often...</td>\n",
       "      <td>2001-06-25T19:19:34Z</td>\n",
       "      <td>2001-06-25T19:19:34Z</td>\n",
       "      <td>[english faggots, pigs liver]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1325</td>\n",
       "      <td>9492</td>\n",
       "      <td>11297</td>\n",
       "      <td>Jen T</td>\n",
       "      <td>So easy and tasty.&nbsp;&nbsp; To make the clean-up even...</td>\n",
       "      <td>2001-06-26T11:23:50Z</td>\n",
       "      <td>2001-06-26T11:23:50Z</td>\n",
       "      <td>[tinfoil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1340</td>\n",
       "      <td>9549</td>\n",
       "      <td>11846</td>\n",
       "      <td>Susie</td>\n",
       "      <td>This is a great way to cook cornish game hens ...</td>\n",
       "      <td>2001-06-27T11:50:26Z</td>\n",
       "      <td>2001-06-27T11:50:26Z</td>\n",
       "      <td>[cornish game hens, vegetables, spices, garlic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect Extracted Ingredients with KG\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:58.713553Z",
     "start_time": "2026-02-13T18:45:58.618960Z"
    }
   },
   "source": [
    "from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS, XSD, SDO, SKOS"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:58.854941Z",
     "start_time": "2026-02-13T18:45:58.789043Z"
    }
   },
   "source": [
    "\n",
    "g = Graph() \n",
    "g.parse(\"vocabulary.ttl\")\n",
    "\n",
    "print(g.serialize(format=\"ttl\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix kgs: <http://kg-course.io/food-nutrition/schema/> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix schema: <https://schema.org/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "kgs:extractedIngredient a rdfs:Class .\n",
      "\n",
      "schema:NutritionInformation a rdfs:Class .\n",
      "\n",
      "schema:Recipe a rdfs:Class .\n",
      "\n",
      "schema:Restaurant a rdfs:Class .\n",
      "\n",
      "schema:Review a rdfs:Class .\n",
      "\n",
      "kgs:averageCostOfTwo a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Restaurant ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "kgs:hasExtractedIngredients a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Review ;\n",
      "    rdfs:range kgs:extractedIngredient .\n",
      "\n",
      "kgs:hasNutrition a rdf:Property ;\n",
      "    rdfs:comment \"Nutrition information for the recipe\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range schema:NutritionInformation .\n",
      "\n",
      "kgs:hasOnlineDelivery a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Restaurant ;\n",
      "    rdfs:range xsd:boolean .\n",
      "\n",
      "kgs:hasReview a rdf:Property ;\n",
      "    rdfs:comment \"Reviews for the recipe\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range schema:Review .\n",
      "\n",
      "kgs:hasSentiment a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Review ;\n",
      "    rdfs:range xsd:float .\n",
      "\n",
      "schema:addressLocality a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Restaurant ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:aggregateRating a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:author a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Review ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:calories a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:carbohydrateContent a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:cholesterolContent a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:cookTime a rdf:Property ;\n",
      "    rdfs:comment \"The cooking time in minutes\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:currenciesAccepted a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Restaurant ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:dateModified a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Review ;\n",
      "    rdfs:range xsd:dateTime .\n",
      "\n",
      "schema:datePublished a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe,\n",
      "        schema:Review ;\n",
      "    rdfs:range xsd:dateTime .\n",
      "\n",
      "schema:fatContent a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:fiberContent a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:image a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:anyURI .\n",
      "\n",
      "schema:keywords a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:name a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe,\n",
      "        schema:Restaurant ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:prepTime a rdf:Property ;\n",
      "    rdfs:comment \"The preparation time in minutes\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:proteinContent a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:recipeCategory a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:recipeCuisine a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:recipeIngredient a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:recipeInstructions a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Recipe ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:reviewBody a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Review ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:saturatedFatContent a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:servesCuisine a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Restaurant ;\n",
      "    rdfs:range xsd:string .\n",
      "\n",
      "schema:sodiumContent a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:starRating a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:Restaurant ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "schema:sugarContent a rdf:Property ;\n",
      "    rdfs:comment \"None\"^^xsd:string ;\n",
      "    rdfs:domain schema:NutritionInformation ;\n",
      "    rdfs:range xsd:decimal .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:58.993023Z",
     "start_time": "2026-02-13T18:45:58.978105Z"
    }
   },
   "source": [
    "BASE = Namespace(\"http://kg-course.io/food-nutrition/\")\n",
    "KGS = Namespace(\"http://kg-course.io/food-nutrition/schema/\")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify KG with Extracted Ingredients related property and class"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:59.017495Z",
     "start_time": "2026-02-13T18:45:58.995607Z"
    }
   },
   "source": [
    "# # Add class for Extracted Ingredients\n",
    "# g.add((KGS.extractedIngredient, RDF.type, RDFS.Class))\n",
    "#\n",
    "# # Add property for connecting Review and Extracted Ingredient\n",
    "# g.add((KGS.hasExtractedIngredients, RDF.type, RDF.Property))\n",
    "# g.add((KGS.hasExtractedIngredients, RDFS.domain, SDO.Review))\n",
    "# g.add((KGS.hasExtractedIngredient, RDFS.range, KGS.extractredIngredient))\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrich KG with reviews and extracted ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:59.023756Z",
     "start_time": "2026-02-13T18:45:59.018501Z"
    }
   },
   "source": [
    "def add_review(g, review):\n",
    "    review_uri = URIRef(BASE[\"review/\" + str(review[\"ReviewId\"])])\n",
    "    recipe_uri = URIRef(BASE[\"recipe/\" + str(review[\"RecipeId\"])])\n",
    "\n",
    "    g.add((review_uri, RDF.type, SDO.Review))\n",
    "    g.add((review_uri, SDO.author, Literal(review[\"AuthorId\"], datatype=XSD.string)))\n",
    "    g.add((review_uri, SDO.reviewBody, Literal(review[\"Review\"], datatype=XSD.string)))\n",
    "    g.add((review_uri, SDO.datePublished, Literal(review[\"DateSubmitted\"], datatype=XSD.dateTime)))\n",
    "    g.add((review_uri, SDO.dateModified, Literal(review[\"DateModified\"], datatype=XSD.dateTime)))\n",
    "    g.add((recipe_uri, KGS.hasReview, review_uri))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:45:59.060224Z",
     "start_time": "2026-02-13T18:45:59.024302Z"
    }
   },
   "source": [
    "index = 0 # unique identifier for an extracted ingredient\n",
    "# save ingredient-ingredient_uri pairs in a dictionary, as we will need them later\n",
    "ingredient_dict = {}\n",
    "for _, row in reviews_ingredients_df.iterrows():\n",
    "    review_uri = URIRef(BASE[\"review/\" + str(row[\"ReviewId\"])])\n",
    "    recipe_uri = URIRef(BASE[\"recipe/\" + str(row[\"RecipeId\"])])\n",
    "\n",
    "    # We also need to add reviews we are using to the graph\n",
    "    add_review(g, row)\n",
    "\n",
    "    for ingredient in row[\"extracted_ingredients\"]:\n",
    "        ingredient_uri = URIRef(BASE[\"extractedIngredient/\" + str(index)])\n",
    "\n",
    "        # link extracted ingredients to review\n",
    "        g.add((ingredient_uri, RDF.type, KGS.extractedIngredient))\n",
    "        g.add((review_uri, KGS.hasExtractedIngredient, ingredient_uri))\n",
    "        g.add((ingredient_uri, RDFS.label, Literal(ingredient, datatype=XSD.string)))\n",
    "\n",
    "        ingredient_dict[ingredient] = ingredient_uri\n",
    "\n",
    "        index += 1\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Sentiment Analysis\n",
    "For the Sentiment analysis we are going to use [cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) classification model. It was trained on posts from Twitter, which are short and often informal, which makes them similar to reviews, so this model is a perfect fit for our needs. The model output has 3 labels: Negative, Neutral, Positive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:02.954227Z",
     "start_time": "2026-02-13T18:45:59.060650Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig, pipeline\n",
    "import numpy as np\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderleonidas/Maastricht University/AI Masters/KEN4256 Building and Mining Knowledge Graphs/fluffy_octo_spoon/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:02.970739Z",
     "start_time": "2026-02-13T18:46:02.966134Z"
    }
   },
   "source": [
    "# Use softmax to normalize the output to probability distribution\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:05.260240Z",
     "start_time": "2026-02-13T18:46:02.971054Z"
    }
   },
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# Using tokenizer and config provided by the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 201/201 [00:00<00:00, 1173.65it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]             \n",
      "\u001B[1mRobertaForSequenceClassification LOAD REPORT\u001B[0m from: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "roberta.pooler.dense.weight     | UNEXPECTED |  | \n",
      "roberta.pooler.dense.bias       | UNEXPECTED |  | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:06.056806Z",
     "start_time": "2026-02-13T18:46:05.277754Z"
    }
   },
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:11.525642Z",
     "start_time": "2026-02-13T18:46:06.082481Z"
    }
   },
   "source": [
    "results = classifier(reviews_ingredients_df[\"Review\"].to_list(), batch_size=32, truncation=True)\n",
    "\n",
    "labels = np.array([res['label'] for res in results])\n",
    "\n",
    "scores = np.array([res['score'] for res in results])\n",
    "\n",
    "reviews_ingredients_df['sentimentLabel'] = labels\n",
    "reviews_ingredients_df['confidenceScore'] = scores\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect sentiment scores results to the graph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:11.567880Z",
     "start_time": "2026-02-13T18:46:11.543792Z"
    }
   },
   "source": [
    "for _, row in reviews_ingredients_df.iterrows():\n",
    "    g.add((URIRef(BASE[\"review/\" + str(row[\"ReviewId\"])]), KGS.hasSentiment, Literal(row[\"confidenceScore\"], datatype=XSD.float)))"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Connect Extracted Ingredients with WikiData\n",
    " Create extractedIngredient class and link all the ingredients extracted from reviews to their corresponding reviews with extractedFrom property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using helper methods from lab 3 for creating and searching vector store"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:12.125349Z",
     "start_time": "2026-02-13T18:46:11.574298Z"
    }
   },
   "source": [
    "# import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "# Create vector store\n",
    "def create_vector_store(embedding_model, texts=None, metadata=None):\n",
    "    if texts is None or len(texts) == 0:\n",
    "        raise ValueError(\"Text data cannot be empty when initializing the vector store.\")\n",
    "\n",
    "    # Add embeddings and metadata to FAISS\n",
    "    vector_store = FAISS.from_texts(texts, embedding_model, metadatas=metadata or [])\n",
    "    return vector_store\n",
    "\n",
    "# Search in FAISS Vector Store\n",
    "def search_vector_store(vector_store, query, embedding_model, top_k=5):\n",
    "    results, score = vector_store.similarity_search_with_score(query, k=top_k)[0]\n",
    "    return results, score"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:12.164802Z",
     "start_time": "2026-02-13T18:46:12.141374Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "with open('data/ingredients_wikidata.json', 'r', encoding='UTF-8') as json_file:\n",
    "     ingredients_wiki = json.load(json_file)\n",
    "\n",
    "ingredients_wiki[:10]\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item': 'http://www.wikidata.org/entity/Q10987',\n",
       "  'itemLabel': 'honey',\n",
       "  'itemDescription': 'sweet food made by bees mostly using nectar from flowers'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q12106',\n",
       "  'itemLabel': 'Triticum',\n",
       "  'itemDescription': 'genus of plants (focus on taxonomy here, not on agriculture)'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q13186',\n",
       "  'itemLabel': 'raisin',\n",
       "  'itemDescription': 'dried grape'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q27855',\n",
       "  'itemLabel': 'Mytilus edulis',\n",
       "  'itemDescription': 'species of mollusc'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q28165',\n",
       "  'itemLabel': 'cinnamon',\n",
       "  'itemDescription': 'spice obtained from the inner bark of several tree species from the genus Cinnamomum'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q29476',\n",
       "  'itemLabel': 'baking powder',\n",
       "  'itemDescription': 'dry chemical leavening agent'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q36465',\n",
       "  'itemLabel': 'flour',\n",
       "  'itemDescription': 'powder which is made by grinding cereal grains'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q41534',\n",
       "  'itemLabel': 'starch',\n",
       "  'itemDescription': 'carbohydrate consisting of a large number of glucose units joined by glycosidic bond'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q45422',\n",
       "  'itemLabel': 'yeast',\n",
       "  'itemDescription': 'informal group of fungi'},\n",
       " {'item': 'http://www.wikidata.org/entity/Q80235',\n",
       "  'itemLabel': 'Tamarindus indica',\n",
       "  'itemDescription': 'species of plant, Tamarind'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:12.172303Z",
     "start_time": "2026-02-13T18:46:12.167472Z"
    }
   },
   "source": [
    "# Formatting the input texts for embedding.\n",
    "\n",
    "def format_text(json_data):\n",
    "    texts = [f\"\"\"{i.get('itemLabel', \" \")}: {i.get('itemDescription', \" \")}\"\"\"\n",
    "                     for i in json_data]\n",
    "    metadata = [{\"label\": item.get('itemLabel', ''),\n",
    "                  \"description\": item.get(\"itemDescription\", ''),\n",
    "                  \"item\": item.get('item', '')}\n",
    "                 for item in json_data]\n",
    "\n",
    "    return (texts, metadata)\n",
    "text, metadata = format_text(ingredients_wiki)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:21.858209Z",
     "start_time": "2026-02-13T18:46:12.172603Z"
    }
   },
   "source": [
    "# Pick an embedding model\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "# Embed texts\n",
    "%time embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "%time vector_store = create_vector_store(embedding_model, text, metadata)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 391/391 [00:00<00:00, 1210.86it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001B[1mBertModel LOAD REPORT\u001B[0m from: BAAI/bge-large-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 358 ms, sys: 610 ms, total: 969 ms\n",
      "Wall time: 4.9 s\n",
      "CPU times: user 683 ms, sys: 182 ms, total: 864 ms\n",
      "Wall time: 4.76 s\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector store always tries to provide us with an answer, so if it can't find a decent match with the query it still provides with the closest it can find. To avoid too much unrelated links we skip results with score(distance) higher than 0.5. This number was chosen more or less by vibe, after looking at which scores correspond to which results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:22.724278Z",
     "start_time": "2026-02-13T18:46:21.885107Z"
    }
   },
   "source": [
    "ingredients_linking = {}\n",
    "for _, row in reviews_ingredients_df.head(10).iterrows():\n",
    "    for ingredient in row[\"extracted_ingredients\"]:\n",
    "        results, score = search_vector_store(vector_store, ingredient, embedding_model, top_k=1)\n",
    "\n",
    "        if score > 0.5:\n",
    "            continue\n",
    "\n",
    "        ingredients_linking[ingredient] = {'matched-label': results.metadata.get('label',''),\n",
    "                                        'wikidata-iri': results.metadata.get('item',''),\n",
    "                                        \"score\": score}\n",
    "        \n",
    "        # add extracted links from wikidata to their corresponding entities in the graph\n",
    "        g.add((ingredient_dict[ingredient], SKOS.closeMatch, URIRef(results.metadata.get('item', ''))))\n",
    "\n",
    "ingredients_linking\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cornstarch': {'matched-label': 'corn starch',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q3393961',\n",
       "  'score': np.float32(0.33861506)},\n",
       " 'chicken sausage': {'matched-label': 'chicken sausage meat',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q107246470',\n",
       "  'score': np.float32(0.3144497)},\n",
       " 'mushrooms': {'matched-label': 'dried mushrooms',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q11702846',\n",
       "  'score': np.float32(0.39636096)},\n",
       " 'roast beef': {'matched-label': 'roast',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q899561',\n",
       "  'score': np.float32(0.20075789)},\n",
       " 'pork': {'matched-label': 'pork liver',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q18384179',\n",
       "  'score': np.float32(0.33809114)},\n",
       " 'beef': {'matched-label': 'roast',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q899561',\n",
       "  'score': np.float32(0.41034186)},\n",
       " 'chicken': {'matched-label': 'chicken egg',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q15260613',\n",
       "  'score': np.float32(0.45251915)},\n",
       " 'soy milk': {'matched-label': 'soy whey',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q131919578',\n",
       "  'score': np.float32(0.47098488)},\n",
       " 'egg beaters': {'matched-label': 'beaten egg',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q137719046',\n",
       "  'score': np.float32(0.38854823)},\n",
       " 'butter': {'matched-label': 'butter substitute',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q107261742',\n",
       "  'score': np.float32(0.46078265)},\n",
       " 'curry powder': {'matched-label': 'curry powder',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q1144935',\n",
       "  'score': np.float32(0.16015139)},\n",
       " 'raisins': {'matched-label': 'raisin',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q13186',\n",
       "  'score': np.float32(0.34029233)},\n",
       " 'light cream': {'matched-label': 'Cream',\n",
       "  'wikidata-iri': 'http://www.wikidata.org/entity/Q21045264',\n",
       "  'score': np.float32(0.3358978)}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Integrating external KG"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:22.765199Z",
     "start_time": "2026-02-13T18:46:22.739413Z"
    }
   },
   "source": [
    "with open('data/recipe_cuisine_wikidata.json', 'r', encoding='UTF-8') as json_file:\n",
    "     recipe_cuisine = json.load(json_file)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:22.785936Z",
     "start_time": "2026-02-13T18:46:22.766633Z"
    }
   },
   "source": [
    "# Add recipeCuisine property to recipes\n",
    "# g.add((SDO.recipeCuisine, RDF.type, RDF.Property))\n",
    "# g.add((SDO.recipeCuisine, RDFS.domain, SDO.Recipe))\n",
    "# g.add((SDO.recipeCuisine, RDFS.range, XSD.string))\n",
    "\n",
    "for dict in recipe_cuisine:\n",
    "    g.add((URIRef(dict[\"recipe\"]), RDF.type, SDO.Recipe))\n",
    "    g.add((URIRef(dict[\"recipe\"]), SDO.recipeCuisine, Literal(dict[\"cuisineLabel_l\"], datatype=XSD.string)))"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:46:35.958619Z",
     "start_time": "2026-02-13T18:46:22.786283Z"
    }
   },
   "source": [
    "# save the unstructured graph we created\n",
    "g.serialize(destination=\"KEN4256-unstructured-KG-Team6.ttl\", format=\"ttl\")\n",
    "\n",
    "structured_g = Graph()\n",
    "structured_g.parse(\"KEN4256-structured-KG-Team6.ttl\")\n",
    "\n",
    "g_combined = structured_g + g\n",
    "\n",
    "g_combined.serialize(destination=\"KEN4256-integrated-KG-Team6.ttl\", format=\"ttl\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Na4470c7fd58745398159a15a1419136c (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
